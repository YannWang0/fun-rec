
向量召回
========

在前一章中，我们学习了协同过滤技术，特别是矩阵分解。该方法的核心思想是通过学习用户和物品的隐向量来预测偏好，这本质上是将离散的ID映射为连续的向量。这种向量化表示是本章将要讨论的向量召回技术的基础。

然而，矩阵分解仍然面临一些局限：它是一个相对简单的线性模型，通过用户向量和物品向量的内积来预测评分，表达能力有限；它主要依赖用户-物品交互矩阵，难以融入更多的特征信息（如用户画像、物品属性、上下文信息等）；在面对数亿用户和数千万商品的工业级规模时，完整交互矩阵的处理和冷启动问题仍然是挑战。

为了突破这些局限，向量召回技术应运而生。它继承并发展了矩阵分解的向量化思想，但将其推向了更深、更广的维度。其核心洞察是：既然向量表示如此强大，为什么不用更复杂的模型（如深度神经网络）来学习向量？为什么不融入更多的特征信息？为什么不借鉴其他领域（如自然语言处理）的成功经验？

这种思想的灵感尤其来自NLP领域的嵌入（Embedding）技术。Word2Vec通过分析大量文本中词语的共现关系，能够为每个词学习一个稠密的向量表示，使得语义相近的词在向量空间中距离更近。这种嵌入技术的核心价值在于，它能够将离散的符号映射到连续的向量空间中，让“距离”具有了语义意义。向量召回正是将这一思想与矩阵分解的理念相结合，将用户和物品都映射到同一个向量空间中，让“距离”代表“相似度”。

在向量空间中，推荐问题得到了根本性的简化。原本需要遍历巨大交互矩阵的召回过程，转变为在高维向量空间中根据一个“查询”向量快速搜索出距离最近的K个物品向量。这种转变不仅大幅提升了计算效率，还通过向量的表示能力捕捉到了更深层次的语义相似性。

向量召回技术主要沿着两条路径发展。\ **I2I（Item-to-Item）召回**\ （:numref:`I2I`\ ）专注于计算物品与物品之间的相似性。\ **U2I（User-to-Item）召回**\ （:numref:`U2I`\ ）则直接匹配用户与物品。

接下来，我们将深入探讨这两大技术路径的演进历程，看看工业界是如何在实践中不断完善和创新这些核心思想的。

.. toctree::
   :maxdepth: 1

   1.i2i.md
   2.u2i.md
   3.summary.md
